//! Workflow Orchestrator Service
//!
//! Extracted from the monolithic `IrisAgent` to handle high-level workflow orchestration,
//! tool coordination, and intelligent context gathering.

use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fmt::Write;
use std::sync::Arc;

use crate::agents::{
    core::AgentContext,
    tools::{AgentTool, ToolRegistry},
};
use crate::context::CommitContext;
use crate::{
    iris_status_analysis, iris_status_expansion, iris_status_planning, iris_status_synthesis,
    iris_status_tool,
};

use super::{LLMService, ResponseParser};

/// High-level workflow orchestrator for intelligent agent operations
#[derive(Clone)]
pub struct WorkflowOrchestrator {
    llm_service: Arc<LLMService>,
    tool_registry: Arc<ToolRegistry>,
    parser: ResponseParser,
}

/// Intelligence context gathered through LLM analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IntelligentContext {
    pub files_with_relevance: Vec<FileRelevance>,
    pub change_summary: String,
    pub technical_analysis: String,
    pub project_insights: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileRelevance {
    pub path: String,
    pub relevance_score: f32,
    pub analysis: String,
    pub key_changes: Vec<String>,
    pub impact_assessment: String,
}

/// Plan for tool execution generated by the agent
#[derive(Debug, Clone)]
pub struct ToolPlan {
    pub tool_name: String,
    pub operation: Option<String>,
    pub parameters: HashMap<String, serde_json::Value>,
    pub reason: String,
}

/// Result from tool execution
#[derive(Debug, Clone)]
pub struct ToolResult {
    pub tool_name: String,
    pub operation: Option<String>,
    pub result: serde_json::Value,
    pub reason: String,
}

/// Workflow execution result
#[derive(Debug, Clone)]
pub struct WorkflowResult {
    pub context: IntelligentContext,
    pub tool_results: Vec<ToolResult>,
    pub execution_time: std::time::Duration,
}

impl WorkflowOrchestrator {
    pub fn new(llm_service: Arc<LLMService>, tool_registry: Arc<ToolRegistry>) -> Self {
        Self {
            llm_service,
            tool_registry,
            parser: ResponseParser::new(),
        }
    }

    /// Gather intelligent context using LLM-driven tool selection and usage
    pub async fn gather_context_with_tools(
        &self,
        context: &AgentContext,
    ) -> Result<IntelligentContext> {
        crate::log_debug!(
            "üß† Orchestrator: Starting intelligent context analysis with agent-driven tool selection"
        );

        // Step 1: Let the agent decide which tools to use
        crate::log_debug!("ü§ñ Orchestrator: Planning tool usage strategy");
        iris_status_planning!();
        let tool_plan = self.plan_tool_usage_for_context_analysis(context).await?;
        crate::log_debug!(
            "üìã Orchestrator: Agent planned {} tool operations",
            tool_plan.len()
        );

        // Step 2: Execute the planned tool calls
        crate::log_debug!("üîß Orchestrator: Executing agent-planned tool calls");
        let tool_results = self.execute_planned_tool_calls(context, &tool_plan).await?;
        crate::log_debug!(
            "‚úÖ Orchestrator: Completed {} tool operations",
            tool_results.len()
        );

        // Step 3: Use LLM to synthesize tool results into intelligent context
        crate::log_debug!("ü§ñ Orchestrator: Synthesizing tool results with LLM");
        iris_status_synthesis!();
        let synthesis_prompt = Self::build_tool_synthesis_prompt(&tool_results);
        crate::log_debug!(
            "üõ†Ô∏è Orchestrator: Synthesis prompt built - {} chars",
            synthesis_prompt.len()
        );

        let intelligence_result = self.llm_service.analyze(&synthesis_prompt).await?;
        crate::log_debug!(
            "ü§ñ Orchestrator: LLM synthesis response received - {} chars",
            intelligence_result.len()
        );

        // Step 4: Parse the synthesized analysis
        crate::log_debug!("üîç Orchestrator: Parsing synthesized analysis result");
        iris_status_analysis!();

        // For now, fall back to basic git context to maintain compatibility
        let git_context = context.git_repo.get_git_info(&context.config).await?;
        let intelligent_context =
            self.parse_intelligence_result(&intelligence_result, &git_context)?;

        crate::log_debug!(
            "‚úÖ Orchestrator: Intelligent context gathered via agent-driven tools - {} files analyzed",
            intelligent_context.files_with_relevance.len()
        );

        Ok(intelligent_context)
    }

    /// Let the agent plan which tools to use for context analysis
    async fn plan_tool_usage_for_context_analysis(
        &self,
        _context: &AgentContext,
    ) -> Result<Vec<ToolPlan>> {
        crate::log_debug!("ü§ñ Orchestrator: Agent planning tool usage strategy");

        // Get available tools
        let available_tools: Vec<String> = self
            .tool_registry
            .list_tools()
            .iter()
            .map(|tool_id| {
                if let Some(tool) = self.tool_registry.get_tool(tool_id) {
                    format!("{}: {}", tool.name(), tool.description())
                } else {
                    format!("{tool_id}: Unknown tool")
                }
            })
            .collect();

        crate::log_debug!(
            "üîß Orchestrator: Available tools: {}",
            available_tools.len()
        );

        // Create initial tool planning prompt
        let planning_prompt = format!(
            "You are Iris, an intelligent AI assistant specialized in Git workflow automation and analysis. Create an initial plan for tools to use to gather comprehensive context.\n\n\
            Your Task: Analyze Git changes to understand their purpose, impact, and relevance for generating a high-quality commit message.\n\n\
            Available tools at your disposal:\n{}\n\n\
            Repository context:\n\
            - This is a Git repository with staged changes\n\
            - You need to understand what changed and why\n\
            - You should gather enough context to assess file relevance and change impact\n\
            - You can expand or adjust this plan as you discover more context\n\n\
            As Iris, respond with a JSON array of tool calls in the order you want to execute them:\n\
            [\n\
              {{\n\
                \"tool_name\": \"Git Operations\",\n\
                \"operation\": \"diff\",\n\
                \"parameters\": {{\"from_ref\": \"HEAD~1\", \"to_ref\": \"HEAD\"}},\n\
                \"reason\": \"I need to see the actual code changes to understand what was modified\",\n\
                \"priority\": \"high\"\n\
              }}\n\
            ]\n\n\
            Note: For Git Operations with \"diff\" operation, always include \"from_ref\" and \"to_ref\" parameters.\n\
            Start with 2-3 essential tool calls. You can expand your plan based on what you discover.",
            available_tools.join("\n")
        );

        crate::log_debug!("ü§ñ Orchestrator: Sending tool planning request to LLM");
        let planning_result = self.llm_service.analyze(&planning_prompt).await?;
        crate::log_debug!(
            "üìã Orchestrator: Tool planning response received - {} chars",
            planning_result.len()
        );

        // Parse the tool plan
        let tool_plan = Self::parse_tool_plan(&planning_result);
        crate::log_debug!(
            "üìã Orchestrator: Parsed {} planned tool operations",
            tool_plan.len()
        );

        Ok(tool_plan)
    }

    /// Execute the planned tool calls with dynamic plan adjustment
    async fn execute_planned_tool_calls(
        &self,
        context: &AgentContext,
        initial_plan: &[ToolPlan],
    ) -> Result<Vec<ToolResult>> {
        let mut results = Vec::new();
        let mut current_plan = initial_plan.to_vec();
        let mut executed_tools = std::collections::HashSet::new();

        crate::log_debug!(
            "üîß Orchestrator: Starting adaptive tool execution with {} initial tools",
            current_plan.len()
        );

        while !current_plan.is_empty() {
            // Execute the next tool in the plan
            let plan = current_plan.remove(0);
            let plan_key = format!(
                "{}:{}",
                plan.tool_name,
                plan.operation.as_deref().unwrap_or("default")
            );

            // Skip if we've already executed this exact tool+operation combination
            if executed_tools.contains(&plan_key) {
                crate::log_debug!(
                    "‚è≠Ô∏è Orchestrator: Skipping already executed tool: {}",
                    plan_key
                );
                continue;
            }

            crate::log_debug!(
                "üîß Orchestrator: Executing tool: {} ({})",
                plan.tool_name,
                plan.reason
            );
            iris_status_tool!(&plan.tool_name, &plan.reason);

            // Find the tool by name
            let tool = self
                .find_tool_by_name(&plan.tool_name)
                .ok_or_else(|| anyhow::anyhow!("Tool not found: {}", plan.tool_name))?;

            // Execute the tool with planned parameters
            let mut params = plan.parameters.clone();
            if let Some(operation) = &plan.operation {
                params.insert(
                    "operation".to_string(),
                    serde_json::Value::String(operation.clone()),
                );
            }

            match tool.execute(context, &params).await {
                Ok(result) => {
                    crate::log_debug!("‚úÖ Orchestrator: Tool call completed: {}", plan.tool_name);
                    executed_tools.insert(plan_key);

                    let tool_result = ToolResult {
                        tool_name: plan.tool_name.clone(),
                        operation: plan.operation.clone(),
                        result,
                        reason: plan.reason.clone(),
                    };

                    results.push(tool_result.clone());

                    // After each tool execution, check if we need to expand the plan
                    if results.len() <= 2 {
                        // Only expand during early execution
                        crate::log_debug!(
                            "ü§ñ Orchestrator: Checking if plan needs expansion based on new context"
                        );
                        iris_status_expansion!();
                        let expanded_plan = self
                            .expand_plan_based_on_context(context, &results, &current_plan)
                            .await?;
                        if !expanded_plan.is_empty() {
                            crate::log_debug!(
                                "üìã Orchestrator: Plan expanded with {} additional tools",
                                expanded_plan.len()
                            );
                            current_plan.extend(expanded_plan);
                        }
                    }
                }
                Err(e) => {
                    crate::log_debug!(
                        "‚ùå Orchestrator: Tool call failed for {}: {}",
                        plan.tool_name,
                        e
                    );
                    // Continue with other tools even if one fails
                }
            }
        }

        crate::log_debug!(
            "üéØ Orchestrator: Completed {} tool executions through adaptive planning",
            results.len()
        );
        Ok(results)
    }

    /// Find a tool by its display name
    fn find_tool_by_name(&self, name: &str) -> Option<Arc<dyn AgentTool>> {
        // First try direct ID lookup for common cases
        let id_mapping = match name {
            "Git Operations" => Some("git"),
            "File Analyzer" => Some("file_analyzer"),
            "Code Search" => Some("code_search"),
            "Workspace Management" => Some("workspace"),
            _ => None,
        };

        if let Some(id) = id_mapping {
            if let Some(tool) = self.tool_registry.get_tool(id) {
                return Some(tool);
            }
        }

        // Fallback to scanning all tools by name
        for tool_id in self.tool_registry.list_tools() {
            if let Some(tool) = self.tool_registry.get_tool(&tool_id) {
                if tool.name() == name {
                    return Some(tool);
                }
            }
        }
        None
    }

    /// Expand the plan based on discovered context
    async fn expand_plan_based_on_context(
        &self,
        _context: &AgentContext,
        current_results: &[ToolResult],
        remaining_plan: &[ToolPlan],
    ) -> Result<Vec<ToolPlan>> {
        // Analyze current results to determine if we need more tools
        let mut context_summary = String::new();
        for result in current_results {
            writeln!(
                context_summary,
                "Tool '{}' revealed: {}",
                result.tool_name,
                match &result.result {
                    serde_json::Value::Object(obj) => {
                        obj.get("content").and_then(|v| v.as_str()).map_or_else(
                            || "Complex data structure".to_string(),
                            |s| s.chars().take(200).collect::<String>(),
                        )
                    }
                    _ => "Non-object result".to_string(),
                }
            )
            .unwrap();
        }

        // Get available tools not in current plan
        let planned_tools: std::collections::HashSet<String> =
            remaining_plan.iter().map(|p| p.tool_name.clone()).collect();
        let available_tools: Vec<String> = self
            .tool_registry
            .list_tools()
            .iter()
            .filter_map(|tool_id| {
                if let Some(tool) = self.tool_registry.get_tool(tool_id) {
                    if planned_tools.contains(tool.name()) {
                        None
                    } else {
                        Some(format!("{}: {}", tool.name(), tool.description()))
                    }
                } else {
                    None
                }
            })
            .collect();

        if available_tools.is_empty() {
            crate::log_debug!("ü§ñ Orchestrator: No additional tools available for plan expansion");
            return Ok(Vec::new());
        }

        let expansion_prompt = format!(
            "You are Iris, analyzing the context you've discovered so far. Based on what you've learned, \
            determine if you need additional tools to get a complete understanding.\n\n\
            Context you've discovered so far:\n{}\n\n\
            Your remaining planned tools:\n{}\n\n\
            Additional tools available to you:\n{}\n\n\
            As Iris, should you add more tools to your plan? If yes, respond with a JSON array of additional tool calls. \
            If you have enough context, respond with an empty array [].\n\n\
            Focus on tools that will provide missing context or deeper analysis for your understanding.",
            context_summary,
            remaining_plan
                .iter()
                .map(|p| format!("{} ({})", p.tool_name, p.reason))
                .collect::<Vec<_>>()
                .join(", "),
            available_tools.join("\n")
        );

        crate::log_debug!("ü§ñ Orchestrator: Requesting plan expansion from LLM");
        let expansion_result = self.llm_service.analyze(&expansion_prompt).await?;
        crate::log_debug!(
            "üìã Orchestrator: Plan expansion response received - {} chars",
            expansion_result.len()
        );

        let expanded_tools = Self::parse_tool_plan(&expansion_result);
        crate::log_debug!(
            "üìã Orchestrator: Parsed {} additional tools for plan expansion",
            expanded_tools.len()
        );

        Ok(expanded_tools)
    }

    /// Build prompt to synthesize tool results into intelligent context
    fn build_tool_synthesis_prompt(tool_results: &[ToolResult]) -> String {
        let mut prompt = String::from(
            "You are Iris, an expert AI assistant synthesizing information from multiple tools to understand Git changes.\n\n\
            Your task is to analyze the tool results and provide intelligent insights about file relevance, change purpose, and overall impact.\n\n\
            Tool Results:\n\n",
        );

        for (i, result) in tool_results.iter().enumerate() {
            write!(
                prompt,
                "=== TOOL RESULT {} ===\n\
                Tool: {}\n\
                Operation: {}\n\
                Purpose: {}\n\
                Result:\n{}\n\n",
                i + 1,
                result.tool_name,
                result.operation.as_deref().unwrap_or("N/A"),
                result.reason,
                serde_json::to_string_pretty(&result.result)
                    .unwrap_or_else(|_| "Unable to serialize".to_string())
            )
            .unwrap();
        }

        prompt.push_str(
            "Based on these tool results, as Iris provide your analysis in this JSON format:\n\
            {\n\
              \"files\": [\n\
                {\n\
                  \"path\": \"file_path\",\n\
                  \"relevance_score\": 0.85,\n\
                  \"analysis\": \"What changed and why it matters\",\n\
                  \"key_changes\": [\"change 1\", \"change 2\"],\n\
                  \"impact_assessment\": \"How this affects the system\"\n\
                }\n\
              ],\n\
              \"change_summary\": \"Overall purpose of these changes\",\n\
              \"technical_analysis\": \"Implementation details and patterns\",\n\
              \"project_insights\": \"How this fits into the larger codebase\"\n\
            }",
        );

        prompt
    }

    /// Parse tool planning response into structured tool plan
    fn parse_tool_plan(planning_result: &str) -> Vec<ToolPlan> {
        crate::log_debug!("üìã Orchestrator: Parsing tool plan from LLM response");

        // Try to parse JSON response
        if let Ok(parsed) = serde_json::from_str::<serde_json::Value>(planning_result) {
            if let Some(array) = parsed.as_array() {
                let mut tool_plan = Vec::new();

                for item in array {
                    if let (Some(tool_name), Some(reason)) = (
                        item.get("tool_name").and_then(|v| v.as_str()),
                        item.get("reason").and_then(|v| v.as_str()),
                    ) {
                        let operation = item
                            .get("operation")
                            .and_then(|v| v.as_str())
                            .map(std::string::ToString::to_string);
                        let parameters = item
                            .get("parameters")
                            .and_then(|v| v.as_object())
                            .map(|obj| obj.iter().map(|(k, v)| (k.clone(), v.clone())).collect())
                            .unwrap_or_default();

                        tool_plan.push(ToolPlan {
                            tool_name: tool_name.to_string(),
                            operation,
                            parameters,
                            reason: reason.to_string(),
                        });
                    }
                }

                crate::log_debug!(
                    "‚úÖ Orchestrator: Successfully parsed {} tool operations",
                    tool_plan.len()
                );
                return tool_plan;
            }
        }

        // Fallback: create basic tool plan if parsing fails
        crate::log_debug!("‚ö†Ô∏è Orchestrator: Failed to parse tool plan, using fallback");
        let mut git_params = HashMap::new();
        git_params.insert(
            "from_ref".to_string(),
            serde_json::Value::String("HEAD~1".to_string()),
        );
        git_params.insert(
            "to_ref".to_string(),
            serde_json::Value::String("HEAD".to_string()),
        );

        vec![ToolPlan {
            tool_name: "Git Operations".to_string(),
            operation: Some("diff".to_string()),
            parameters: git_params,
            reason: "Get code changes for analysis".to_string(),
        }]
    }

    /// Parse LLM intelligence result into structured context
    fn parse_intelligence_result(
        &self,
        result: &str,
        git_context: &CommitContext,
    ) -> Result<IntelligentContext> {
        crate::log_debug!(
            "üîç Orchestrator: Parsing LLM analysis result: {}",
            result.chars().take(200).collect::<String>()
        );

        // Try to parse JSON response using our parser
        let parsed_response: serde_json::Value = self.parser.parse_json_response(result)?;

        let files_with_relevance: Vec<FileRelevance> = parsed_response
            .get("files")
            .and_then(|f| f.as_array())
            .map_or_else(
                || {
                    // Fallback: create basic context with equal relevance
                    crate::log_debug!("‚ö†Ô∏è Orchestrator: Using fallback file analysis");
                    git_context
                        .staged_files
                        .iter()
                        .enumerate()
                        .map(|(i, file)| {
                            crate::log_debug!(
                                "üìÑ Orchestrator: Creating fallback analysis for file {}: {}",
                                i + 1,
                                file.path
                            );
                            FileRelevance {
                                path: file.path.clone(),
                                relevance_score: 0.7, // Default relevance
                                analysis: format!("File {} was modified", file.path),
                                key_changes: vec!["Content changes detected".to_string()],
                                impact_assessment: "Part of the overall changeset".to_string(),
                            }
                        })
                        .collect()
                },
                |files| {
                    crate::log_debug!("üìä Orchestrator: Processing {} file analyses from LLM", files.len());
                    files
                        .iter()
                        .enumerate()
                        .filter_map(|(i, file)| {
                            let file_result = Some(FileRelevance {
                                path: file.get("path")?.as_str()?.to_string(),
                                #[allow(clippy::cast_possible_truncation, clippy::as_conversions)]
                                relevance_score: file.get("relevance_score")?.as_f64()? as f32,
                                analysis: file.get("analysis")?.as_str()?.to_string(),
                                key_changes: file
                                    .get("key_changes")?
                                    .as_array()?
                                    .iter()
                                    .filter_map(|v| {
                                        v.as_str().map(std::string::ToString::to_string)
                                    })
                                    .collect(),
                                impact_assessment: file
                                    .get("impact_assessment")?
                                    .as_str()?
                                    .to_string(),
                            });

                            if let Some(ref fr) = file_result {
                                crate::log_debug!(
                                    "üìÑ Orchestrator: File {} analysis - relevance: {:.2}, {} key changes",
                                    fr.path,
                                    fr.relevance_score,
                                    fr.key_changes.len()
                                );
                            } else {
                                crate::log_debug!("‚ö†Ô∏è Orchestrator: Failed to parse file analysis #{}", i + 1);
                            }

                            file_result
                        })
                        .collect()
                },
            );

        let change_summary = parsed_response
            .get("change_summary")
            .and_then(|v| v.as_str())
            .unwrap_or("Changes analyzed")
            .to_string();

        let technical_analysis = parsed_response
            .get("technical_analysis")
            .and_then(|v| v.as_str())
            .unwrap_or("Technical implementation details")
            .to_string();

        let project_insights = parsed_response
            .get("project_insights")
            .and_then(|v| v.as_str())
            .unwrap_or("Project context and fit")
            .to_string();

        crate::log_debug!(
            "‚úÖ Orchestrator: Successfully parsed intelligent context with {} file analyses",
            files_with_relevance.len()
        );

        Ok(IntelligentContext {
            files_with_relevance,
            change_summary,
            technical_analysis,
            project_insights,
        })
    }

    /// Gather intelligent context (wrapper for compatibility)
    pub async fn gather_intelligent_context(
        &self,
        context: &AgentContext,
    ) -> Result<IntelligentContext> {
        self.gather_context_with_tools(context).await
    }

    /// Build commit context from agent context and intelligent context
    pub async fn build_commit_context(
        &self,
        context: &AgentContext,
        _intelligent_context: &IntelligentContext,
    ) -> Result<CommitContext> {
        // Create a basic commit context using the git repo
        let git_repo = &context.git_repo;
        let config = &context.config;

        // This is a simplified version - in a real implementation,
        // you'd want to properly construct the CommitContext
        let commit_context = git_repo.get_git_info(config).await?;

        // For now, return a basic context - this could be enhanced
        // to incorporate the intelligent context data
        Ok(commit_context)
    }
}
