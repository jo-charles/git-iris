//! Workflow Orchestrator Service
//!
//! Extracted from the monolithic `IrisAgent` to handle high-level workflow orchestration,
//! tool coordination, and intelligent context gathering.

use anyhow::Result;
use futures::future;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fmt::Write;
use std::sync::Arc;

use crate::agents::{
    core::AgentContext,
    tools::{AgentTool, ToolRegistry},
};
use crate::context::CommitContext;

use super::{LLMService, ResponseParser};

/// High-level workflow orchestrator for intelligent agent operations
#[derive(Clone)]
pub struct WorkflowOrchestrator {
    llm_service: Arc<LLMService>,
    tool_registry: Arc<ToolRegistry>,
    parser: ResponseParser,
}

/// Intelligence context gathered through LLM analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IntelligentContext {
    pub files_with_relevance: Vec<FileRelevance>,
    pub change_summary: String,
    pub technical_analysis: String,
    pub project_insights: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileRelevance {
    pub path: String,
    pub relevance_score: f32,
    pub analysis: String,
    pub key_changes: Vec<String>,
    pub impact_assessment: String,
}

/// Plan for tool execution generated by the agent
#[derive(Debug, Clone)]
pub struct ToolPlan {
    pub tool_name: String,
    pub operation: Option<String>,
    pub parameters: HashMap<String, serde_json::Value>,
    pub reason: String,
}

/// Result from tool execution
#[derive(Debug, Clone)]
pub struct ToolResult {
    pub tool_name: String,
    pub operation: Option<String>,
    pub result: serde_json::Value,
    pub reason: String,
}

/// Workflow execution result
#[derive(Debug, Clone)]
pub struct WorkflowResult {
    pub context: IntelligentContext,
    pub tool_results: Vec<ToolResult>,
    pub execution_time: std::time::Duration,
}

impl WorkflowOrchestrator {
    pub fn new(llm_service: Arc<LLMService>, tool_registry: Arc<ToolRegistry>) -> Self {
        Self {
            llm_service,
            tool_registry,
            parser: ResponseParser::new(),
        }
    }

    /// Gather intelligent context using LLM-driven tool selection and usage
    pub async fn gather_context_with_tools(
        &self,
        context: &AgentContext,
    ) -> Result<IntelligentContext> {
        crate::log_debug!("üîç Starting intelligent context gathering...");

        // Phase 1: Get agent-planned tool usage strategy
        let plan = self.plan_tool_usage_for_context_analysis(context).await?;

        // Phase 2: Execute the planned tools
        let tool_results = self.execute_planned_tool_calls(context, &plan).await?;

        // Phase 3: Synthesize results using LLM
        crate::log_debug!("ü§ñ Synthesizing {} tool results...", tool_results.len());

        let synthesis_prompt = Self::build_tool_synthesis_prompt(&tool_results);
        let synthesis_result = self.llm_service.analyze(&synthesis_prompt).await?;

        // Phase 4: Parse the intelligent analysis
        let intelligent_context = self
            .parse_intelligence_result(&synthesis_result, context)
            .await?;

        crate::log_debug!("‚úÖ Context gathering completed");

        Ok(intelligent_context)
    }

    /// Let the agent plan which tools to use for context analysis
    async fn plan_tool_usage_for_context_analysis(
        &self,
        _context: &AgentContext,
    ) -> Result<Vec<ToolPlan>> {
        crate::log_debug!("ü§ñ Planning tool usage strategy...");

        // Get available tools
        let available_tools: Vec<String> = self
            .tool_registry
            .list_tools()
            .iter()
            .map(|tool_id| {
                if let Some(tool) = self.tool_registry.get_tool(tool_id) {
                    format!("{}: {}", tool.name(), tool.description())
                } else {
                    format!("{tool_id}: Unknown tool")
                }
            })
            .collect();

        // Create initial tool planning prompt
        let planning_prompt = format!(
            "You are Iris, an intelligent AI assistant specialized in Git workflow automation and analysis. Create an initial plan for tools to use to gather comprehensive context.\n\n\
            Your Task: Analyze Git changes to understand their purpose, impact, and relevance for generating a high-quality commit message.\n\n\
            Available tools at your disposal:\n{}\n\n\
            Repository context:\n\
            - This is a Git repository with staged changes\n\
            - You need to understand what changed and why\n\
            - You should gather enough context to assess file relevance and change impact\n\
            - You can expand or adjust this plan as you discover more context\n\n\
            TOOL PARAMETER REQUIREMENTS:\n\
            Git Operations:\n\
            - diff: requires \"from_ref\" and \"to_ref\" (e.g., \"HEAD~1\", \"HEAD\")\n\
            - status: optional \"include_unstaged\" (boolean)\n\
            File Analyzer:\n\
            - analyze: requires \"file_paths\" (array of strings)\n\
            Code Search:\n\
            - search: requires \"query\" (string) and \"search_type\" (\"function\", \"class\", \"text\")\n\
            Workspace Management:\n\
            - list: optional \"path\" (string)\n\n\
            IMPORTANT: Respond with ONLY a valid JSON array, nothing else. No explanations, no markdown formatting, just the raw JSON.\n\n\
            Expected format:\n\
            [\n\
              {{\n\
                \"tool_name\": \"Git Operations\",\n\
                \"operation\": \"diff\",\n\
                \"parameters\": {{\"from_ref\": \"HEAD~1\", \"to_ref\": \"HEAD\"}},\n\
                \"reason\": \"I need to see the actual code changes to understand what was modified\"\n\
              }}\n\
            ]\n\n\
            Available tool names: \"Git Operations\", \"File Analyzer\", \"Code Search\", \"Workspace Management\"\n\
            Common operations: \"diff\", \"status\", \"analyze\", \"search\", \"list\"\n\
            \n\
            Start with 2-3 essential tool calls:",
            available_tools.join("\n")
        );

        let planning_result = self.llm_service.analyze(&planning_prompt).await?;

        // Parse the tool plan
        let tool_plan = Self::parse_tool_plan(&planning_result);

        // Log the actual plan that was generated
        crate::log_debug!("üìã Generated tool execution plan:");
        for (i, plan) in tool_plan.iter().enumerate() {
            let operation_info = if let Some(op) = &plan.operation {
                format!(" ({op})")
            } else {
                String::new()
            };
            crate::log_debug!(
                "  {}. {} {} - {}",
                i + 1,
                plan.tool_name,
                operation_info,
                plan.reason
            );
        }

        Ok(tool_plan)
    }

    /// Execute the planned tool calls with dynamic plan adjustment and parallel execution where possible
    async fn execute_planned_tool_calls(
        &self,
        context: &AgentContext,
        initial_plan: &[ToolPlan],
    ) -> Result<Vec<ToolResult>> {
        let mut results = Vec::new();
        let mut current_plan = initial_plan.to_vec();
        let mut executed_tools = std::collections::HashSet::new();

        crate::log_debug!("üîß Executing {} planned tools...", current_plan.len());

        while !current_plan.is_empty() {
            // Group tools that can be executed in parallel (no interdependencies)
            let (parallel_batch, remaining_plan) = self.extract_parallel_batch(&current_plan);
            current_plan = remaining_plan;

            if parallel_batch.len() > 1 {
                crate::log_debug!("‚ö° Running {} tools in parallel...", parallel_batch.len());
            }

            // Execute the parallel batch
            let mut batch_futures = Vec::new();
            for plan in parallel_batch {
                let plan_key = format!(
                    "{}:{}",
                    plan.tool_name,
                    plan.operation.as_deref().unwrap_or("default")
                );

                // Skip if we've already executed this exact tool+operation combination
                if executed_tools.contains(&plan_key) {
                    crate::log_debug!("‚è≠Ô∏è Skipping duplicate: {}", plan_key);
                    continue;
                }

                let operation_display = if let Some(op) = &plan.operation {
                    format!(" ({op})")
                } else {
                    String::new()
                };
                crate::log_debug!("üîß Running: {}{}", plan.tool_name, operation_display);

                // Skip tool execution status messages - only show LLM-generated ones

                // Find the tool by name
                let tool = self
                    .find_tool_by_name(&plan.tool_name)
                    .ok_or_else(|| anyhow::anyhow!("Tool not found: {}", plan.tool_name))?;

                // Prepare parameters
                let mut params = plan.parameters.clone();
                if let Some(operation) = &plan.operation {
                    params.insert(
                        "operation".to_string(),
                        serde_json::Value::String(operation.clone()),
                    );
                }

                // Create future for this tool execution
                let context_clone = context.clone();
                let tool_clone = tool.clone();
                let plan_clone = plan.clone();
                let plan_key_clone = plan_key.clone();

                let future = async move {
                    let result = tool_clone.execute(&context_clone, &params).await;
                    (plan_clone, plan_key_clone, result)
                };

                batch_futures.push(future);
            }

            // Execute all tools in this batch concurrently
            let batch_results = future::join_all(batch_futures).await;

            // Process results from the parallel batch
            for (plan, plan_key, execution_result) in batch_results {
                match execution_result {
                    Ok(result) => {
                        // Log a brief summary of what we got back
                        let result_summary = match &result {
                            serde_json::Value::Object(obj) => {
                                if let Some(content) = obj.get("content").and_then(|v| v.as_str()) {
                                    let lines = content.lines().count();
                                    let chars = content.len();
                                    if chars > 500 {
                                        format!("{lines}+ lines, {chars}+ chars")
                                    } else {
                                        format!("{lines} lines, {chars} chars")
                                    }
                                } else if let Some(files) =
                                    obj.get("files").and_then(|v| v.as_array())
                                {
                                    format!("{} files analyzed", files.len())
                                } else {
                                    "structured data".to_string()
                                }
                            }
                            serde_json::Value::Array(arr) => format!("{} items", arr.len()),
                            serde_json::Value::String(s) => {
                                let lines = s.lines().count();
                                format!("{lines} lines")
                            }
                            _ => "data".to_string(),
                        };

                        crate::log_debug!("‚úÖ {}: {}", plan.tool_name, result_summary);
                        executed_tools.insert(plan_key);

                        let tool_result = ToolResult {
                            tool_name: plan.tool_name.clone(),
                            operation: plan.operation.clone(),
                            result,
                            reason: plan.reason.clone(),
                        };

                        results.push(tool_result);
                    }
                    Err(e) => {
                        crate::log_debug!("‚ùå {} failed: {}", plan.tool_name, e);
                        // Continue with other tools even if one fails
                    }
                }
            }

            // After executing a batch, check if we need to expand the plan
            if results.len() <= 2 && !current_plan.is_empty() {
                // Only expand during early execution and if we have more tools planned
                let expanded_plan = self
                    .expand_plan_based_on_context(context, &results, &current_plan)
                    .await?;
                if !expanded_plan.is_empty() {
                    crate::log_debug!(
                        "üìã Plan expanded with {} additional tools:",
                        expanded_plan.len()
                    );
                    for (i, plan) in expanded_plan.iter().enumerate() {
                        let operation_info = if let Some(op) = &plan.operation {
                            format!(" ({op})")
                        } else {
                            String::new()
                        };
                        crate::log_debug!(
                            "  {}. {}{} - {}",
                            i + 1,
                            plan.tool_name,
                            operation_info,
                            plan.reason
                        );
                    }
                    // Skip plan expansion status - only show LLM-generated ones
                    current_plan.extend(expanded_plan);
                }
            }
        }

        crate::log_debug!("üéØ Completed {} tool executions", results.len());
        Ok(results)
    }

    /// Extract a batch of tools that can be executed in parallel
    fn extract_parallel_batch(&self, plan: &[ToolPlan]) -> (Vec<ToolPlan>, Vec<ToolPlan>) {
        if plan.is_empty() {
            return (Vec::new(), Vec::new());
        }

        // For now, we'll be conservative and only parallelize truly independent tools
        // Tools that are safe to run in parallel:
        // - Different tool types (Git Operations, File Analyzer, Workspace Management)
        // - Same tool type with clearly different purposes/parameters
        // Tools that should be sequential:
        // - Same tool type with same operation (to avoid redundancy)
        // - Code Search that might depend on previous results

        let mut parallel_batch = Vec::new();
        let mut remaining = Vec::new();
        let mut seen_tool_operations = std::collections::HashSet::new();

        for tool_plan in plan {
            // Create a key that identifies this specific tool+operation combination
            let tool_key = match tool_plan.operation.as_ref() {
                Some(op) => format!("{}:{}", tool_plan.tool_name, op),
                None => tool_plan.tool_name.clone(),
            };

            // Check if we've already included this tool+operation type
            if seen_tool_operations.contains(&tool_key) {
                crate::log_debug!("‚è≠Ô∏è Deferring duplicate tool combination: {}", tool_key);
                remaining.push(tool_plan.clone());
                continue;
            }

            let can_parallelize = match tool_plan.tool_name.as_str() {
                "Git Operations" => {
                    // Only allow one Git operation per batch to avoid conflicts
                    !seen_tool_operations
                        .iter()
                        .any(|key: &String| key.starts_with("Git Operations:"))
                }
                "File Analyzer" => {
                    // File analysis is always safe to parallelize
                    true
                }
                "Workspace Management" => {
                    // Workspace operations are generally safe to parallelize
                    true
                }
                "Code Search" => {
                    // Code search might depend on context, be more conservative
                    // Don't parallelize if we already have other tools running
                    parallel_batch.is_empty()
                }
                _ => {
                    // Unknown tools should be sequential for safety
                    false
                }
            };

            if can_parallelize && parallel_batch.len() < 2 {
                // Limit parallel batch size to 2 to avoid overwhelming the system
                parallel_batch.push(tool_plan.clone());
                seen_tool_operations.insert(tool_key);
            } else {
                remaining.push(tool_plan.clone());
            }
        }

        // If we only got one tool in the batch and there are more remaining,
        // grab one more if it's safe to parallelize
        if parallel_batch.len() == 1 && !remaining.is_empty() {
            let first_tool = &parallel_batch[0].tool_name;

            // Look for a complementary tool that's safe to run with the first one
            let mut complementary_idx = None;
            for (i, tool_plan) in remaining.iter().enumerate() {
                let is_complementary = match (first_tool.as_str(), tool_plan.tool_name.as_str()) {
                    ("Git Operations", "Workspace Management") => true,
                    ("Git Operations", "File Analyzer") => false, // File analyzer might depend on git results
                    ("Workspace Management", "Git Operations") => true,
                    ("Workspace Management", "File Analyzer") => true,
                    ("File Analyzer", "Workspace Management") => true,
                    _ => false,
                };

                if is_complementary {
                    complementary_idx = Some(i);
                    break;
                }
            }

            if let Some(idx) = complementary_idx {
                let complementary_tool = remaining.remove(idx);
                parallel_batch.push(complementary_tool);
            }
        }

        (parallel_batch, remaining)
    }

    /// Find a tool by its display name
    fn find_tool_by_name(&self, name: &str) -> Option<Arc<dyn AgentTool>> {
        // First try direct ID lookup for common cases
        let id_mapping = match name {
            "Git Operations" => Some("git"),
            "File Analyzer" => Some("file_analyzer"),
            "Code Search" => Some("code_search"),
            "Workspace Management" => Some("workspace"),
            _ => None,
        };

        if let Some(id) = id_mapping {
            if let Some(tool) = self.tool_registry.get_tool(id) {
                return Some(tool);
            }
        }

        // Fallback to scanning all tools by name
        for tool_id in self.tool_registry.list_tools() {
            if let Some(tool) = self.tool_registry.get_tool(&tool_id) {
                if tool.name() == name {
                    return Some(tool);
                }
            }
        }
        None
    }

    /// Expand the plan based on discovered context
    async fn expand_plan_based_on_context(
        &self,
        _context: &AgentContext,
        current_results: &[ToolResult],
        remaining_plan: &[ToolPlan],
    ) -> Result<Vec<ToolPlan>> {
        // Analyze current results to determine if we need more tools
        let mut context_summary = String::new();
        for result in current_results {
            writeln!(
                context_summary,
                "Tool '{}' revealed: {}",
                result.tool_name,
                match &result.result {
                    serde_json::Value::Object(obj) => {
                        obj.get("content").and_then(|v| v.as_str()).map_or_else(
                            || "Complex data structure".to_string(),
                            |s| s.chars().take(200).collect::<String>(),
                        )
                    }
                    _ => "Non-object result".to_string(),
                }
            )
            .unwrap();
        }

        // Get available tools not in current plan
        let planned_tools: std::collections::HashSet<String> =
            remaining_plan.iter().map(|p| p.tool_name.clone()).collect();
        let available_tools: Vec<String> = self
            .tool_registry
            .list_tools()
            .iter()
            .filter_map(|tool_id| {
                if let Some(tool) = self.tool_registry.get_tool(tool_id) {
                    if planned_tools.contains(tool.name()) {
                        None
                    } else {
                        Some(format!("{}: {}", tool.name(), tool.description()))
                    }
                } else {
                    None
                }
            })
            .collect();

        if available_tools.is_empty() {
            crate::log_debug!("ü§ñ Orchestrator: No additional tools available for plan expansion");
            return Ok(Vec::new());
        }

        let expansion_prompt = format!(
            "TASK: Determine if additional tools are needed for complete context analysis.\n\n\
            DISCOVERED CONTEXT:\n{}\n\n\
            REMAINING PLANNED TOOLS:\n{}\n\n\
            AVAILABLE ADDITIONAL TOOLS:\n{}\n\n\
            INSTRUCTIONS:\n\
            - If you have sufficient context for analysis, return: []\n\
            - If you need more tools, return JSON array with tool specifications\n\
            - Focus only on essential missing information gaps\n\
            - Avoid redundant tool calls\n\n\
            PARAMETER EXAMPLES:\n\
            Git Operations diff: {{\"from_ref\": \"HEAD~1\", \"to_ref\": \"HEAD\"}}\n\
            Git Operations status: {{\"include_unstaged\": true}}\n\
            File Analyzer: {{\"file_paths\": [\"path1\", \"path2\"]}}\n\
            Code Search: {{\"query\": \"function_name\", \"search_type\": \"function\"}}\n\
            Workspace Management: {{\"operation\": \"list\", \"path\": \"src/\"}}\n\n\
            RESPONSE FORMAT (JSON only, no explanations):\n\
            [] OR [\n\
              {{\n\
                \"tool_name\": \"Exact Tool Name\",\n\
                \"operation\": \"operation_name\",\n\
                \"parameters\": {{\"correct_param\": \"value\"}},\n\
                \"reason\": \"Brief reason for this tool\"\n\
              }}\n\
            ]\n\n\
            Valid tool names: \"Git Operations\", \"File Analyzer\", \"Code Search\", \"Workspace Management\"\n\
            Valid operations: \"diff\", \"status\", \"analyze\", \"search\", \"list\"",
            context_summary,
            remaining_plan
                .iter()
                .map(|p| format!("{} ({})", p.tool_name, p.reason))
                .collect::<Vec<_>>()
                .join(", "),
            available_tools.join("\n")
        );

        crate::log_debug!("ü§ñ Orchestrator: Requesting plan expansion from LLM");
        let expansion_result = self.llm_service.analyze(&expansion_prompt).await?;

        // Parse the expanded plan
        let expanded_plan = Self::parse_tool_plan(&expansion_result);
        crate::log_debug!(
            "üìã Orchestrator: Parsed {} additional tool operations",
            expanded_plan.len()
        );

        Ok(expanded_plan)
    }

    /// Build prompt to synthesize tool results into intelligent context
    fn build_tool_synthesis_prompt(tool_results: &[ToolResult]) -> String {
        let mut prompt = String::from(
            "You are Iris, an expert AI assistant synthesizing information from multiple tools to understand Git changes.\n\n\
            Your task is to analyze the tool results and provide intelligent insights about file relevance, change purpose, and overall impact.\n\n\
            Tool Results:\n\n",
        );

        for (i, result) in tool_results.iter().enumerate() {
            write!(
                prompt,
                "=== TOOL RESULT {} ===\n\
                Tool: {}\n\
                Operation: {}\n\
                Purpose: {}\n\
                Result:\n{}\n\n",
                i + 1,
                result.tool_name,
                result.operation.as_deref().unwrap_or("N/A"),
                result.reason,
                serde_json::to_string_pretty(&result.result)
                    .unwrap_or_else(|_| "Unable to serialize".to_string())
            )
            .unwrap();
        }

        prompt.push_str(
            "Based on these tool results, as Iris provide your analysis in this JSON format:\n\
            {\n\
              \"files\": [\n\
                {\n\
                  \"path\": \"file_path\",\n\
                  \"relevance_score\": 0.85,\n\
                  \"analysis\": \"What changed and why it matters\",\n\
                  \"key_changes\": [\"change 1\", \"change 2\"],\n\
                  \"impact_assessment\": \"How this affects the system\"\n\
                }\n\
              ],\n\
              \"change_summary\": \"Overall purpose of these changes\",\n\
              \"technical_analysis\": \"Implementation details and patterns\",\n\
              \"project_insights\": \"How this fits into the larger codebase\"\n\
            }",
        );

        prompt
    }

    /// Parse tool planning response into structured tool plan
    fn parse_tool_plan(planning_result: &str) -> Vec<ToolPlan> {
        crate::log_debug!("üìã Parsing tool plan from LLM response");

        // Log a snippet of what we received for debugging
        let preview = if planning_result.len() > 200 {
            format!("{}...", &planning_result[..200])
        } else {
            planning_result.to_string()
        };
        crate::log_debug!("üìÑ LLM response preview: {}", preview);

        // Try to extract JSON from the response if it's wrapped in text
        let json_content = if let Some(start) = planning_result.find('[') {
            if let Some(end) = planning_result.rfind(']') {
                if end > start {
                    &planning_result[start..=end]
                } else {
                    planning_result
                }
            } else {
                planning_result
            }
        } else {
            planning_result
        };

        // Try to parse JSON response
        match serde_json::from_str::<serde_json::Value>(json_content) {
            Ok(parsed) => {
                if let Some(array) = parsed.as_array() {
                    let mut tool_plan = Vec::new();

                    for item in array {
                        if let (Some(tool_name), Some(reason)) = (
                            item.get("tool_name").and_then(|v| v.as_str()),
                            item.get("reason").and_then(|v| v.as_str()),
                        ) {
                            let operation = item
                                .get("operation")
                                .and_then(|v| v.as_str())
                                .map(std::string::ToString::to_string);
                            let parameters = item
                                .get("parameters")
                                .and_then(|v| v.as_object())
                                .map(|obj| {
                                    obj.iter().map(|(k, v)| (k.clone(), v.clone())).collect()
                                })
                                .unwrap_or_default();

                            tool_plan.push(ToolPlan {
                                tool_name: tool_name.to_string(),
                                operation,
                                parameters,
                                reason: reason.to_string(),
                            });
                        }
                    }

                    if !tool_plan.is_empty() {
                        crate::log_debug!(
                            "‚úÖ Successfully parsed {} tool operations",
                            tool_plan.len()
                        );
                        return tool_plan;
                    }
                }
                crate::log_debug!("‚ö†Ô∏è JSON parsed but no valid tool plans found");
            }
            Err(e) => {
                crate::log_debug!("‚ö†Ô∏è JSON parse failed: {}", e);
                if json_content != planning_result {
                    crate::log_debug!("üìÑ Extracted JSON: {}", json_content);
                }
            }
        }

        // Fallback: create basic tool plan if parsing fails
        crate::log_debug!("üîß Using fallback tool plan");
        let mut git_params = HashMap::new();
        git_params.insert(
            "from_ref".to_string(),
            serde_json::Value::String("HEAD~1".to_string()),
        );
        git_params.insert(
            "to_ref".to_string(),
            serde_json::Value::String("HEAD".to_string()),
        );

        vec![ToolPlan {
            tool_name: "Git Operations".to_string(),
            operation: Some("diff".to_string()),
            parameters: git_params,
            reason: "Get code changes for analysis".to_string(),
        }]
    }

    /// Parse intelligence result into structured context
    async fn parse_intelligence_result(
        &self,
        result: &str,
        context: &AgentContext,
    ) -> Result<IntelligentContext> {
        crate::log_debug!(
            "üîç Orchestrator: Parsing intelligence result ({} chars)",
            result.len()
        );

        // Get git context for fallback
        let git_context = context.git_repo.get_git_info(&context.config).await?;

        // Try to parse JSON response using our parser
        let parsed_response: serde_json::Value = self.parser.parse_json_response(result)?;

        let files_with_relevance: Vec<FileRelevance> = parsed_response
            .get("files")
            .and_then(|f| f.as_array())
            .map_or_else(
                || {
                    // Fallback: create basic context with equal relevance
                    crate::log_debug!("‚ö†Ô∏è Orchestrator: Using fallback file analysis");
                    git_context
                        .staged_files
                        .iter()
                        .map(|file| FileRelevance {
                            path: file.path.clone(),
                            relevance_score: 0.7,
                            analysis: format!("File {} was modified", file.path),
                            key_changes: vec!["Content changes detected".to_string()],
                            impact_assessment: "Part of the overall changeset".to_string(),
                        })
                        .collect()
                },
                |files| {
                    crate::log_debug!(
                        "üìä Orchestrator: Processing {} file analyses from LLM",
                        files.len()
                    );
                    files
                        .iter()
                        .filter_map(|file| {
                            Some(FileRelevance {
                                path: file.get("path")?.as_str()?.to_string(),
                                #[allow(clippy::cast_possible_truncation, clippy::as_conversions)]
                                relevance_score: file.get("relevance_score")?.as_f64()? as f32,
                                analysis: file.get("analysis")?.as_str()?.to_string(),
                                key_changes: file
                                    .get("key_changes")?
                                    .as_array()?
                                    .iter()
                                    .filter_map(|v| v.as_str().map(ToString::to_string))
                                    .collect(),
                                impact_assessment: file
                                    .get("impact_assessment")?
                                    .as_str()?
                                    .to_string(),
                            })
                        })
                        .collect()
                },
            );

        let change_summary = parsed_response
            .get("change_summary")
            .and_then(|v| v.as_str())
            .unwrap_or("Changes analyzed")
            .to_string();

        let technical_analysis = parsed_response
            .get("technical_analysis")
            .and_then(|v| v.as_str())
            .unwrap_or("Technical implementation details")
            .to_string();

        let project_insights = parsed_response
            .get("project_insights")
            .and_then(|v| v.as_str())
            .unwrap_or("Project context and fit")
            .to_string();

        crate::log_debug!(
            "üìã Orchestrator: Parsed {} files with relevance scores",
            files_with_relevance.len()
        );

        Ok(IntelligentContext {
            files_with_relevance,
            change_summary,
            technical_analysis,
            project_insights,
        })
    }

    /// Gather intelligent context (wrapper for compatibility)
    pub async fn gather_intelligent_context(
        &self,
        context: &AgentContext,
    ) -> Result<IntelligentContext> {
        self.gather_context_with_tools(context).await
    }

    /// Build commit context from agent context and intelligent context
    pub async fn build_commit_context(
        &self,
        context: &AgentContext,
        _intelligent_context: &IntelligentContext,
    ) -> Result<CommitContext> {
        // Create a basic commit context using the git repo
        let git_repo = &context.git_repo;
        let config = &context.config;

        // This is a simplified version - in a real implementation,
        // you'd want to properly construct the CommitContext
        let commit_context = git_repo.get_git_info(config).await?;

        // For now, return a basic context - this could be enhanced
        // to incorporate the intelligent context data
        Ok(commit_context)
    }
}
