//! Workflow Orchestrator Service
//!
//! Extracted from the monolithic `IrisAgent` to handle high-level workflow orchestration,
//! tool coordination, and intelligent context gathering.

use anyhow::Result;
use futures::future::BoxFuture;
use futures::{FutureExt, future};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fmt::Write;
use std::sync::Arc;

use crate::agents::{
    core::AgentContext,
    tools::{AgentTool, ToolRegistry},
};
use crate::context::CommitContext;

use super::{LLMService, ResponseParser};

/// High-level workflow orchestrator for intelligent agent operations
#[derive(Clone)]
pub struct WorkflowOrchestrator {
    llm_service: Arc<LLMService>,
    tool_registry: Arc<ToolRegistry>,
    parser: ResponseParser,
}

/// Intelligence context gathered through LLM analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IntelligentContext {
    pub files_with_relevance: Vec<FileRelevance>,
    pub change_summary: String,
    pub technical_analysis: String,
    pub project_insights: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileRelevance {
    pub path: String,
    pub relevance_score: f32,
    pub analysis: String,
    pub key_changes: Vec<String>,
    pub impact_assessment: String,
}

/// Plan for tool execution generated by the agent
#[derive(Debug, Clone)]
pub struct ToolPlan {
    pub tool_name: String,
    pub operation: Option<String>,
    pub parameters: HashMap<String, serde_json::Value>,
    pub reason: String,
}

/// Result from tool execution
#[derive(Debug, Clone)]
pub struct ToolResult {
    pub tool_name: String,
    pub operation: Option<String>,
    pub result: serde_json::Value,
    pub reason: String,
}

/// Workflow execution result
#[derive(Debug, Clone)]
pub struct WorkflowResult {
    pub context: IntelligentContext,
    pub tool_results: Vec<ToolResult>,
    pub execution_time: std::time::Duration,
}

/// Execution state for tool processing
#[derive(Debug)]
struct ExecutionState {
    results: Vec<ToolResult>,
    current_plan: Vec<ToolPlan>,
    executed_tools: std::collections::HashSet<String>,
    failed_tools: std::collections::HashSet<String>,
    plan_expansion_count: usize,
    iteration_count: usize,
}

/// Type alias for complex future type
type ToolExecutionFuture = BoxFuture<'static, (ToolPlan, String, Result<serde_json::Value>)>;

impl WorkflowOrchestrator {
    pub fn new(llm_service: Arc<LLMService>, tool_registry: Arc<ToolRegistry>) -> Self {
        Self {
            llm_service,
            tool_registry,
            parser: ResponseParser::new(),
        }
    }

    /// Gather intelligent context using LLM-driven tool selection and usage
    pub async fn gather_context_with_tools(
        &self,
        context: &AgentContext,
    ) -> Result<IntelligentContext> {
        crate::log_debug!("üîç Starting intelligent context gathering...");

        // Phase 1: Get agent-planned tool usage strategy
        let plan = self.plan_tool_usage_for_context_analysis(context).await?;

        // Phase 2: Execute the planned tools
        let tool_results = self.execute_planned_tool_calls(context, &plan).await?;

        // Phase 3: Synthesize results using LLM
        crate::log_debug!("ü§ñ Synthesizing {} tool results...", tool_results.len());

        // OPTIMIZATION: Skip synthesis for simple cases where we have direct git data
        let has_git_diff = tool_results
            .iter()
            .any(|r| r.tool_name == "Git Operations" && r.operation.as_deref() == Some("diff"));
        let has_file_analysis = tool_results.iter().any(|r| r.tool_name == "File Analyzer");

        // If we have basic git operations, skip synthesis and return raw results
        if (has_git_diff || has_file_analysis) && tool_results.len() <= 4 {
            crate::log_debug!("üéØ Basic operations detected - skipping synthesis for efficiency");

            // Convert tool results directly to IntelligentContext structure
            let mut files_with_relevance = Vec::new();

            for result in &tool_results {
                if result.tool_name == "Git Operations"
                    && result.operation.as_deref() == Some("diff")
                {
                    if let Some(content) = result.result.get("content").and_then(|c| c.as_str()) {
                        // Extract file paths from git diff
                        let file_paths: Vec<&str> = content
                            .lines()
                            .filter(|l| l.starts_with("diff --git"))
                            .filter_map(|l| l.split_whitespace().nth(3))
                            .collect();

                        for path in file_paths {
                            files_with_relevance.push(FileRelevance {
                                path: path.to_string(),
                                relevance_score: 0.9,
                                analysis: "Modified file with staged changes".to_string(),
                                key_changes: vec!["Direct git diff changes".to_string()],
                                impact_assessment: "High - staged for commit".to_string(),
                            });
                        }
                    }
                }
            }

            return Ok(IntelligentContext {
                files_with_relevance,
                change_summary: "Git changes ready for commit generation".to_string(),
                technical_analysis: "Direct tool results bypass synthesis for efficiency"
                    .to_string(),
                project_insights: "Basic operations detected - no additional analysis needed"
                    .to_string(),
            });
        }

        // Only use synthesis for complex cases with many tools
        crate::log_debug!("üß† Complex analysis needed - performing full synthesis");

        let synthesis_prompt = Self::build_tool_synthesis_prompt(&tool_results);
        let synthesis_result = self.llm_service.analyze(&synthesis_prompt).await?;

        // Phase 4: Parse the intelligent analysis
        let intelligent_context = self
            .parse_intelligence_result(&synthesis_result, context)
            .await?;

        crate::log_debug!("‚úÖ Context gathering completed");

        Ok(intelligent_context)
    }

    /// Let the agent plan which tools to use for context analysis
    async fn plan_tool_usage_for_context_analysis(
        &self,
        _context: &AgentContext,
    ) -> Result<Vec<ToolPlan>> {
        crate::log_debug!("ü§ñ Planning tool usage strategy...");

        // Get available tools
        let available_tools: Vec<String> = self
            .tool_registry
            .list_tools()
            .iter()
            .map(|tool_id| {
                if let Some(tool) = self.tool_registry.get_tool(tool_id) {
                    format!("{}: {}", tool.name(), tool.description())
                } else {
                    format!("{tool_id}: Unknown tool")
                }
            })
            .collect();

        // Create initial tool planning prompt - make it more comprehensive to reduce expansion needs
        let planning_prompt = format!(
            "You are Iris, an intelligent AI assistant specialized in Git workflow automation and analysis. Create a COMPREHENSIVE plan for tools to use to gather complete context.\n\n\
            Your Task: Analyze Git changes to understand their purpose, impact, and relevance for generating a high-quality commit message.\n\n\
            Available tools at your disposal:\n{}\n\n\
            Repository context:\n\
            - This is a Git repository with staged changes\n\
            - You need to understand what changed and why\n\
            - Create a COMPLETE plan upfront to avoid multiple rounds of expansion\n\
            - Prioritize essential tools that provide maximum insight\n\n\
            TOOL PARAMETER REQUIREMENTS:\n\
            Git Operations:\n\
            - diff: requires \"from_ref\" and \"to_ref\" (e.g., \"HEAD~1\", \"HEAD\")\n\
            - status: optional \"include_unstaged\" (boolean)\n\
            File Analyzer:\n\
            - analyze: requires \"file_paths\" (array of strings)\n\
            Code Search:\n\
            - search: requires \"query\" (string) and \"search_type\" (\"function\", \"class\", \"text\")\n\
            Workspace Management:\n\
            - list: optional \"path\" (string)\n\n\
            STRATEGIC PLANNING GUIDANCE:\n\
            1. ALWAYS start with Git Operations diff to see what changed\n\
            2. Include Git Operations status to understand staged vs unstaged state\n\
            3. Consider File Analyzer for key modified files\n\
            4. Include Workspace Management to understand project structure\n\
            5. Plan 3-4 essential tools to get comprehensive context in one pass\n\n\
            IMPORTANT: Respond with ONLY a valid JSON array, nothing else. No explanations, no markdown formatting, just the raw JSON.\n\n\
            Expected format:\n\
            [\n\
              {{\n\
                \"tool_name\": \"Git Operations\",\n\
                \"operation\": \"diff\",\n\
                \"parameters\": {{\"from_ref\": \"HEAD~1\", \"to_ref\": \"staged\"}},\n\
                \"reason\": \"See actual staged changes to understand modifications\"\n\
              }},\n\
              {{\n\
                \"tool_name\": \"Git Operations\",\n\
                \"operation\": \"status\",\n\
                \"parameters\": {{\"include_unstaged\": false}},\n\
                \"reason\": \"Get clean status of staged files for commit\"\n\
              }}\n\
            ]\n\n\
            Available tool names: \"Git Operations\", \"File Analyzer\", \"Code Search\", \"Workspace Management\"\n\
            Common operations: \"diff\", \"status\", \"analyze\", \"search\", \"list\"\n\
            \n\
            Create a comprehensive 3-4 tool plan:",
            available_tools.join("\n")
        );

        let planning_result = self.llm_service.fast_analyze(&planning_prompt).await?;

        // Parse the tool plan
        let tool_plan = Self::parse_tool_plan(&planning_result);

        // Log the actual plan that was generated
        crate::log_debug!("üìã Generated tool execution plan:");
        for (i, plan) in tool_plan.iter().enumerate() {
            let operation_info = if let Some(op) = &plan.operation {
                format!(" ({op})")
            } else {
                String::new()
            };
            crate::log_debug!(
                "  {}. {} {} - {}",
                i + 1,
                plan.tool_name,
                operation_info,
                plan.reason
            );
        }

        Ok(tool_plan)
    }

    /// Execute the planned tool calls with dynamic plan adjustment and parallel execution where possible
    async fn execute_planned_tool_calls(
        &self,
        context: &AgentContext,
        initial_plan: &[ToolPlan],
    ) -> Result<Vec<ToolResult>> {
        let mut execution_state = Self::initialize_execution_state(initial_plan);

        crate::log_debug!(
            "üîß Executing {} planned tools...",
            execution_state.current_plan.len()
        );

        while !execution_state.current_plan.is_empty()
            && execution_state.iteration_count < Self::MAX_ITERATIONS
        {
            execution_state.iteration_count += 1;
            crate::log_debug!(
                "üîÑ Iteration {}/{}",
                execution_state.iteration_count,
                Self::MAX_ITERATIONS
            );

            // Execute a batch of tools in parallel
            let batch_results = self
                .execute_tool_batch(context, &mut execution_state)
                .await?;

            // Process the results and update state
            let any_successful = Self::process_batch_results(batch_results, &mut execution_state);

            // Check if we need to expand the plan with additional tools
            if Self::should_expand_plan(&execution_state, any_successful) {
                self.handle_plan_expansion(context, &mut execution_state)
                    .await?;
            } else {
                Self::log_expansion_skip_reason(&execution_state, any_successful);
            }
        }

        Ok(Self::finalize_execution(&execution_state))
    }

    const MAX_PLAN_EXPANSIONS: usize = 3;
    const MAX_ITERATIONS: usize = 10;

    /// Initialize the execution state for tool processing
    fn initialize_execution_state(initial_plan: &[ToolPlan]) -> ExecutionState {
        ExecutionState {
            results: Vec::new(),
            current_plan: initial_plan.to_vec(),
            executed_tools: std::collections::HashSet::new(),
            failed_tools: std::collections::HashSet::new(),
            plan_expansion_count: 0,
            iteration_count: 0,
        }
    }

    /// Execute a batch of tools in parallel
    async fn execute_tool_batch(
        &self,
        context: &AgentContext,
        execution_state: &mut ExecutionState,
    ) -> Result<Vec<(ToolPlan, String, Result<serde_json::Value>)>> {
        // Group tools that can be executed in parallel
        let (parallel_batch, remaining_plan) =
            Self::extract_parallel_batch(&execution_state.current_plan);
        execution_state.current_plan = remaining_plan;

        if parallel_batch.len() > 1 {
            crate::log_debug!("‚ö° Running {} tools in parallel...", parallel_batch.len());
        }

        // Create futures for parallel execution
        let mut batch_futures = Vec::new();
        for plan in parallel_batch {
            if let Some(future) =
                self.create_tool_execution_future(context, &plan, execution_state)?
            {
                batch_futures.push(future);
            }
        }

        // Execute all tools concurrently
        Ok(future::join_all(batch_futures).await)
    }

    /// Create a future for executing a single tool
    fn create_tool_execution_future(
        &self,
        context: &AgentContext,
        plan: &ToolPlan,
        execution_state: &ExecutionState,
    ) -> Result<Option<ToolExecutionFuture>> {
        let plan_key = format!(
            "{}:{}",
            plan.tool_name,
            plan.operation.as_deref().unwrap_or("default")
        );

        // Skip if already executed or failed
        if execution_state.executed_tools.contains(&plan_key) {
            crate::log_debug!("‚è≠Ô∏è Skipping duplicate: {}", plan_key);
            return Ok(None);
        }

        if execution_state.failed_tools.contains(&plan_key) {
            crate::log_debug!("‚è≠Ô∏è Skipping previously failed: {}", plan_key);
            return Ok(None);
        }

        let operation_display = if let Some(op) = &plan.operation {
            format!(" ({op})")
        } else {
            String::new()
        };
        crate::log_debug!("üîß Running: {}{}", plan.tool_name, operation_display);

        // Find the tool and prepare parameters
        let tool = self
            .find_tool_by_name(&plan.tool_name)
            .ok_or_else(|| anyhow::anyhow!("Tool not found: {}", plan.tool_name))?;

        let mut params = plan.parameters.clone();
        if let Some(operation) = &plan.operation {
            params.insert(
                "operation".to_string(),
                serde_json::Value::String(operation.clone()),
            );
        }

        let context_clone = context.clone();
        let tool_clone = tool.clone();
        let plan_clone = plan.clone();
        let plan_key_clone = plan_key.clone();

        Ok(Some(
            async move {
                let result = tool_clone.execute(&context_clone, &params).await;
                (plan_clone, plan_key_clone, result)
            }
            .boxed(),
        ))
    }

    /// Process the results from a batch of tool executions
    fn process_batch_results(
        batch_results: Vec<(ToolPlan, String, Result<serde_json::Value>)>,
        execution_state: &mut ExecutionState,
    ) -> bool {
        let mut any_successful = false;

        for (plan, plan_key, execution_result) in batch_results {
            match execution_result {
                Ok(result) => {
                    let result_summary = Self::create_result_summary(&result);
                    crate::log_debug!("‚úÖ {}: {}", plan.tool_name, result_summary);

                    execution_state.executed_tools.insert(plan_key);
                    any_successful = true;

                    let tool_result = ToolResult {
                        tool_name: plan.tool_name.clone(),
                        operation: plan.operation.clone(),
                        result,
                        reason: plan.reason.clone(),
                    };

                    execution_state.results.push(tool_result);
                }
                Err(e) => {
                    crate::log_debug!("‚ùå {} failed: {}", plan.tool_name, e);
                    execution_state.failed_tools.insert(plan_key);
                }
            }
        }

        any_successful
    }

    /// Create a summary string for a tool execution result
    fn create_result_summary(result: &serde_json::Value) -> String {
        match result {
            serde_json::Value::Object(obj) => {
                if let Some(content) = obj.get("content").and_then(|v| v.as_str()) {
                    let lines = content.lines().count();
                    let chars = content.len();
                    if chars > 500 {
                        format!("{lines}+ lines, {chars}+ chars")
                    } else {
                        format!("{lines} lines, {chars} chars")
                    }
                } else if let Some(files) = obj.get("files").and_then(|v| v.as_array()) {
                    format!("{} files analyzed", files.len())
                } else {
                    "structured data".to_string()
                }
            }
            serde_json::Value::Array(arr) => format!("{} items", arr.len()),
            serde_json::Value::String(s) => {
                let lines = s.lines().count();
                format!("{lines} lines")
            }
            _ => "data".to_string(),
        }
    }

    /// Determine if the plan should be expanded with additional tools
    fn should_expand_plan(execution_state: &ExecutionState, any_successful: bool) -> bool {
        if !any_successful
            || execution_state.plan_expansion_count >= Self::MAX_PLAN_EXPANSIONS
            || execution_state.current_plan.is_empty()
        {
            return false;
        }

        // Check if we have essential minimum for commit generation
        let has_git_diff = execution_state.results.iter().any(|r| {
            r.tool_name == "Git Operations"
                && r.operation.as_deref() == Some("diff")
                && (r.result.get("changed_files").is_some()
                    || r.result
                        .get("content")
                        .is_some_and(|c| c.as_str().is_some_and(|s| s.len() > 50)))
        });

        let has_file_analysis = execution_state.results.iter().any(|r| {
            r.tool_name == "File Analyzer"
                && (r.result.get("files").is_some() || r.result.get("analysis").is_some())
        });

        let essential_context_exists = has_git_diff || has_file_analysis;

        if essential_context_exists {
            crate::log_debug!("üéØ Essential context detected - skipping further expansion");
            false
        } else {
            crate::log_debug!("‚ö†Ô∏è No essential context found - allowing minimal expansion");
            execution_state.current_plan.len() <= 2
        }
    }

    /// Handle plan expansion by requesting additional tools
    async fn handle_plan_expansion(
        &self,
        context: &AgentContext,
        execution_state: &mut ExecutionState,
    ) -> Result<()> {
        execution_state.plan_expansion_count += 1;
        crate::log_debug!(
            "üìã Plan expansion {}/{} - essential information missing from {} results",
            execution_state.plan_expansion_count,
            Self::MAX_PLAN_EXPANSIONS,
            execution_state.results.len()
        );

        let expanded_plan = self
            .expand_plan_based_on_context(
                context,
                &execution_state.results,
                &execution_state.current_plan,
            )
            .await?;

        if expanded_plan.is_empty() {
            crate::log_debug!("üìã No additional tools suggested - context appears sufficient");
        } else {
            crate::log_debug!(
                "üìã Plan expanded with {} additional tools:",
                expanded_plan.len()
            );
            for (i, plan) in expanded_plan.iter().enumerate() {
                let operation_info = if let Some(op) = &plan.operation {
                    format!(" ({op})")
                } else {
                    String::new()
                };
                crate::log_debug!(
                    "  {}. {}{} - {}",
                    i + 1,
                    plan.tool_name,
                    operation_info,
                    plan.reason
                );
            }
            execution_state.current_plan.extend(expanded_plan);
        }

        Ok(())
    }

    /// Log the reason for skipping plan expansion
    fn log_expansion_skip_reason(execution_state: &ExecutionState, any_successful: bool) {
        if execution_state.plan_expansion_count >= Self::MAX_PLAN_EXPANSIONS {
            crate::log_debug!("üö´ Maximum plan expansions reached - stopping expansion");
        } else if !any_successful {
            crate::log_debug!(
                "üö´ No successful tool executions in this batch - stopping expansion"
            );
        } else {
            crate::log_debug!("‚úÖ Sufficient context gathered - skipping plan expansion");
        }
    }

    /// Finalize execution and return results
    fn finalize_execution(execution_state: &ExecutionState) -> Vec<ToolResult> {
        if execution_state.iteration_count >= Self::MAX_ITERATIONS {
            crate::log_debug!("üö´ Maximum iterations reached - stopping execution");
        }

        crate::log_debug!(
            "üéØ Completed {} tool executions in {} iterations",
            execution_state.results.len(),
            execution_state.iteration_count
        );

        execution_state.results.clone()
    }

    /// Extract a batch of tools that can be executed in parallel
    fn extract_parallel_batch(plan: &[ToolPlan]) -> (Vec<ToolPlan>, Vec<ToolPlan>) {
        if plan.is_empty() {
            return (Vec::new(), Vec::new());
        }

        // For now, we'll be conservative and only parallelize truly independent tools
        // Tools that are safe to run in parallel:
        // - Different tool types (Git Operations, File Analyzer, Workspace Management)
        // - Same tool type with clearly different purposes/parameters
        // Tools that should be sequential:
        // - Same tool type with same operation (to avoid redundancy)
        // - Code Search that might depend on previous results

        let mut parallel_batch = Vec::new();
        let mut remaining = Vec::new();
        let mut seen_tool_operations = std::collections::HashSet::new();

        for tool_plan in plan {
            // Create a key that identifies this specific tool+operation combination
            let tool_key = match tool_plan.operation.as_ref() {
                Some(op) => format!("{}:{}", tool_plan.tool_name, op),
                None => tool_plan.tool_name.clone(),
            };

            // Check if we've already included this tool+operation type
            if seen_tool_operations.contains(&tool_key) {
                crate::log_debug!("‚è≠Ô∏è Deferring duplicate tool combination: {}", tool_key);
                remaining.push(tool_plan.clone());
                continue;
            }

            let can_parallelize = match tool_plan.tool_name.as_str() {
                "Git Operations" => {
                    // Only allow one Git operation per batch to avoid conflicts
                    !seen_tool_operations
                        .iter()
                        .any(|key: &String| key.starts_with("Git Operations:"))
                }
                "File Analyzer" | "Workspace Management" => {
                    // File analysis and workspace operations are safe to parallelize
                    true
                }
                "Code Search" => {
                    // Code search might depend on context, be more conservative
                    // Don't parallelize if we already have other tools running
                    parallel_batch.is_empty()
                }
                _ => {
                    // Unknown tools should be sequential for safety
                    false
                }
            };

            if can_parallelize && parallel_batch.len() < 2 {
                // Limit parallel batch size to 2 to avoid overwhelming the system
                parallel_batch.push(tool_plan.clone());
                seen_tool_operations.insert(tool_key);
            } else {
                remaining.push(tool_plan.clone());
            }
        }

        // If we only got one tool in the batch and there are more remaining,
        // grab one more if it's safe to parallelize
        if parallel_batch.len() == 1 && !remaining.is_empty() {
            let first_tool = &parallel_batch[0].tool_name;

            // Look for a complementary tool that's safe to run with the first one
            let mut complementary_idx = None;
            for (i, tool_plan) in remaining.iter().enumerate() {
                let is_complementary = match (first_tool.as_str(), tool_plan.tool_name.as_str()) {
                    ("Git Operations" | "File Analyzer", "Workspace Management")
                    | ("Workspace Management", "Git Operations" | "File Analyzer") => true,
                    // File analyzer might depend on git results, so don't run in parallel
                    _ => false,
                };

                if is_complementary {
                    complementary_idx = Some(i);
                    break;
                }
            }

            if let Some(idx) = complementary_idx {
                let complementary_tool = remaining.remove(idx);
                parallel_batch.push(complementary_tool);
            }
        }

        (parallel_batch, remaining)
    }

    /// Find a tool by its display name
    fn find_tool_by_name(&self, name: &str) -> Option<Arc<dyn AgentTool>> {
        // First try direct ID lookup for common cases
        let id_mapping = match name {
            "Git Operations" => Some("git"),
            "File Analyzer" => Some("file_analyzer"),
            "Code Search" => Some("code_search"),
            "Workspace Management" => Some("workspace"),
            _ => None,
        };

        if let Some(id) = id_mapping {
            if let Some(tool) = self.tool_registry.get_tool(id) {
                return Some(tool);
            }
        }

        // Fallback to scanning all tools by name
        for tool_id in self.tool_registry.list_tools() {
            if let Some(tool) = self.tool_registry.get_tool(&tool_id) {
                if tool.name() == name {
                    return Some(tool);
                }
            }
        }
        None
    }

    /// Expand the plan based on discovered context
    async fn expand_plan_based_on_context(
        &self,
        _context: &AgentContext,
        current_results: &[ToolResult],
        remaining_plan: &[ToolPlan],
    ) -> Result<Vec<ToolPlan>> {
        // Analyze current results to determine if we need more tools
        let mut context_summary = String::new();
        for result in current_results {
            writeln!(
                context_summary,
                "Tool '{}' revealed: {}",
                result.tool_name,
                match &result.result {
                    serde_json::Value::Object(obj) => {
                        obj.get("content").and_then(|v| v.as_str()).map_or_else(
                            || "Complex data structure".to_string(),
                            |s| s.chars().take(200).collect::<String>(),
                        )
                    }
                    _ => "Non-object result".to_string(),
                }
            )
            .unwrap();
        }

        // Get available tools not in current plan
        let planned_tools: std::collections::HashSet<String> =
            remaining_plan.iter().map(|p| p.tool_name.clone()).collect();
        let available_tools: Vec<String> = self
            .tool_registry
            .list_tools()
            .iter()
            .filter_map(|tool_id| {
                if let Some(tool) = self.tool_registry.get_tool(tool_id) {
                    if planned_tools.contains(tool.name()) {
                        None
                    } else {
                        Some(format!("{}: {}", tool.name(), tool.description()))
                    }
                } else {
                    None
                }
            })
            .collect();

        if available_tools.is_empty() {
            crate::log_debug!("ü§ñ Orchestrator: No additional tools available for plan expansion");
            return Ok(Vec::new());
        }

        let expansion_prompt = format!(
            "TASK: Determine if additional tools are needed for complete context analysis.\n\n\
            CURRENT CONTEXT SUMMARY:\n{}\n\n\
            REMAINING PLANNED TOOLS:\n{}\n\n\
            ANALYSIS: Review the discovered context. Do we have:\n\
            ‚úì Git changes (diff content)?\n\
            ‚úì File status information?\n\
            ‚úì Understanding of modified files?\n\
            \n\
            INSTRUCTIONS:\n\
            - If sufficient context exists for commit analysis: return []\n\
            - If critical information is missing: return minimal JSON array\n\
            - Focus ONLY on essential gaps, avoid redundancy\n\
            - Maximum 2 additional tools\n\n\
            AVAILABLE TOOLS:\n{}\n\n\
            RESPONSE FORMAT (JSON only):\n\
            [] OR [\n\
              {{\n\
                \"tool_name\": \"Tool Name\",\n\
                \"operation\": \"operation\",\n\
                \"parameters\": {{\"param\": \"value\"}},\n\
                \"reason\": \"Critical missing information\"\n\
              }}\n\
            ]",
            context_summary.trim(),
            remaining_plan
                .iter()
                .map(|p| p.tool_name.to_string())
                .collect::<Vec<_>>()
                .join(", "),
            available_tools.join("\n")
        );

        crate::log_debug!("ü§ñ Orchestrator: Requesting plan expansion from LLM");
        let expansion_result = self.llm_service.fast_analyze(&expansion_prompt).await?;

        // Parse the expanded plan
        let expanded_plan = Self::parse_tool_plan(&expansion_result);
        crate::log_debug!(
            "üìã Orchestrator: Parsed {} additional tool operations",
            expanded_plan.len()
        );

        Ok(expanded_plan)
    }

    /// Build prompt to synthesize tool results into intelligent context
    fn build_tool_synthesis_prompt(tool_results: &[ToolResult]) -> String {
        let mut prompt = Self::create_base_synthesis_prompt();
        Self::add_tool_results_to_prompt(&mut prompt, tool_results);
        Self::add_diff_content_to_prompt(&mut prompt, tool_results);
        Self::add_json_format_to_prompt(&mut prompt);
        prompt
    }

    /// Create the base prompt for tool result synthesis
    fn create_base_synthesis_prompt() -> String {
        String::from(
            "You are Iris, an expert AI assistant synthesizing information from multiple tools to understand Git changes.\n\n\
            Your task is to analyze the tool results and provide intelligent insights about file relevance, change purpose, and overall impact.\n\n\
            Tool Results Summary:\n\n",
        )
    }

    /// Add tool result summaries to the synthesis prompt
    fn add_tool_results_to_prompt(prompt: &mut String, tool_results: &[ToolResult]) {
        for (i, result) in tool_results.iter().enumerate() {
            let result_summary = Self::summarize_tool_result(result);

            write!(
                prompt,
                "=== TOOL RESULT {} ===\n\
                Tool: {} ({})\n\
                Purpose: {}\n\
                Summary: {}\n\n",
                i + 1,
                result.tool_name,
                result.operation.as_deref().unwrap_or("default"),
                result.reason,
                result_summary
            )
            .unwrap();
        }
    }

    /// Create a concise summary for a single tool result
    fn summarize_tool_result(result: &ToolResult) -> String {
        match result.tool_name.as_str() {
            "Git Operations" => Self::summarize_git_operation_result(result),
            "File Analyzer" => Self::summarize_file_analyzer_result(result),
            "Workspace Management" => Self::summarize_workspace_result(result),
            _ => "Tool execution completed".to_string(),
        }
    }

    /// Summarize Git Operations tool result
    fn summarize_git_operation_result(result: &ToolResult) -> String {
        if let Some(content) = result.result.get("content").and_then(|c| c.as_str()) {
            match result.operation.as_deref() {
                Some("diff") => {
                    let lines = content.lines().count();
                    let additions = content.lines().filter(|l| l.starts_with('+')).count();
                    let deletions = content.lines().filter(|l| l.starts_with('-')).count();

                    // Extract just the file paths and key changes
                    let files: Vec<&str> = content
                        .lines()
                        .filter(|l| l.starts_with("diff --git"))
                        .filter_map(|l| l.split_whitespace().nth(3))
                        .collect();

                    format!(
                        "Git diff: {} files changed, {} lines total, +{} -{} changes. Files: {}",
                        files.len(),
                        lines,
                        additions,
                        deletions,
                        files.join(", ")
                    )
                }
                Some("status") => {
                    let staged_count = content.lines().filter(|l| l.contains("staged")).count();
                    format!("Git status: {staged_count} staged files ready for commit")
                }
                _ => format!("Git operation: {} lines of output", content.lines().count()),
            }
        } else {
            "Git operation completed".to_string()
        }
    }

    /// Summarize File Analyzer tool result
    fn summarize_file_analyzer_result(result: &ToolResult) -> String {
        if let Some(files) = result.result.get("files").and_then(|f| f.as_array()) {
            format!(
                "File analysis: {} files analyzed with detailed insights",
                files.len()
            )
        } else {
            "File analysis completed".to_string()
        }
    }

    /// Summarize Workspace Management tool result
    fn summarize_workspace_result(result: &ToolResult) -> String {
        if let Some(content) = result.result.get("content").and_then(|c| c.as_str()) {
            let lines = content.lines().count();
            format!("Workspace structure: {lines} items discovered")
        } else {
            "Workspace structure analyzed".to_string()
        }
    }

    /// Add essential git diff content to the synthesis prompt
    fn add_diff_content_to_prompt(prompt: &mut String, tool_results: &[ToolResult]) {
        if let Some(git_diff) = tool_results
            .iter()
            .find(|r| r.tool_name == "Git Operations" && r.operation.as_deref() == Some("diff"))
        {
            if let Some(content) = git_diff.result.get("content").and_then(|c| c.as_str()) {
                let truncated_diff = Self::truncate_diff_content(content);
                write!(prompt, "=== KEY DIFF CONTENT ===\n{truncated_diff}\n\n").unwrap();
            }
        }
    }

    /// Truncate diff content to essential changes only
    fn truncate_diff_content(content: &str) -> String {
        if content.len() > 2000 {
            let lines: Vec<&str> = content.lines().collect();
            let essential_lines: Vec<&str> = lines
                .iter()
                .filter(|l| {
                    l.starts_with("diff --git")
                        || l.starts_with("@@")
                        || (l.starts_with('+') && !l.starts_with("+++"))
                        || (l.starts_with('-') && !l.starts_with("---"))
                })
                .take(50) // Limit to 50 essential lines
                .copied()
                .collect();

            format!(
                "{}\n... (diff truncated for efficiency) ...",
                essential_lines.join("\n")
            )
        } else {
            content.to_string()
        }
    }

    /// Add the expected JSON output format to the synthesis prompt
    fn add_json_format_to_prompt(prompt: &mut String) {
        prompt.push_str(
            "Based on these tool results, as Iris provide your analysis in this JSON format:\n\
            {\n\
              \"files\": [\n\
                {\n\
                  \"path\": \"file_path\",\n\
                  \"relevance_score\": 0.85,\n\
                  \"analysis\": \"What changed and why it matters\",\n\
                  \"key_changes\": [\"change 1\", \"change 2\"],\n\
                  \"impact_assessment\": \"How this affects the system\"\n\
                }\n\
              ],\n\
              \"change_summary\": \"Overall purpose of these changes\",\n\
              \"technical_analysis\": \"Implementation details and patterns\",\n\
              \"project_insights\": \"How this fits into the larger codebase\"\n\
            }",
        );
    }

    /// Parse tool planning response into structured tool plan
    fn parse_tool_plan(planning_result: &str) -> Vec<ToolPlan> {
        crate::log_debug!("üìã Parsing tool plan from LLM response");

        // Log a snippet of what we received for debugging
        let preview = if planning_result.len() > 200 {
            format!("{}...", &planning_result[..200])
        } else {
            planning_result.to_string()
        };
        crate::log_debug!("üìÑ LLM response preview: {}", preview);

        // Try to extract JSON from the response if it's wrapped in text
        let json_content = if let Some(start) = planning_result.find('[') {
            if let Some(end) = planning_result.rfind(']') {
                if end > start {
                    &planning_result[start..=end]
                } else {
                    planning_result
                }
            } else {
                planning_result
            }
        } else {
            planning_result
        };

        // Try to parse JSON response
        match serde_json::from_str::<serde_json::Value>(json_content) {
            Ok(parsed) => {
                if let Some(array) = parsed.as_array() {
                    let mut tool_plan = Vec::new();

                    for item in array {
                        if let (Some(tool_name), Some(reason)) = (
                            item.get("tool_name").and_then(|v| v.as_str()),
                            item.get("reason").and_then(|v| v.as_str()),
                        ) {
                            let operation = item
                                .get("operation")
                                .and_then(|v| v.as_str())
                                .map(std::string::ToString::to_string);
                            let parameters = item
                                .get("parameters")
                                .and_then(|v| v.as_object())
                                .map(|obj| {
                                    obj.iter().map(|(k, v)| (k.clone(), v.clone())).collect()
                                })
                                .unwrap_or_default();

                            tool_plan.push(ToolPlan {
                                tool_name: tool_name.to_string(),
                                operation,
                                parameters,
                                reason: reason.to_string(),
                            });
                        }
                    }

                    if !tool_plan.is_empty() {
                        crate::log_debug!(
                            "‚úÖ Successfully parsed {} tool operations",
                            tool_plan.len()
                        );
                        return tool_plan;
                    }
                }
                crate::log_debug!("‚ö†Ô∏è JSON parsed but no valid tool plans found");
            }
            Err(e) => {
                crate::log_debug!("‚ö†Ô∏è JSON parse failed: {}", e);
                if json_content != planning_result {
                    crate::log_debug!("üìÑ Extracted JSON: {}", json_content);
                }
            }
        }

        // Fallback: create basic tool plan if parsing fails
        crate::log_debug!("üîß Using fallback tool plan");
        let mut git_params = HashMap::new();
        git_params.insert(
            "from_ref".to_string(),
            serde_json::Value::String("HEAD~1".to_string()),
        );
        git_params.insert(
            "to_ref".to_string(),
            serde_json::Value::String("HEAD".to_string()),
        );

        vec![ToolPlan {
            tool_name: "Git Operations".to_string(),
            operation: Some("diff".to_string()),
            parameters: git_params,
            reason: "Get code changes for analysis".to_string(),
        }]
    }

    /// Parse intelligence result into structured context
    async fn parse_intelligence_result(
        &self,
        result: &str,
        context: &AgentContext,
    ) -> Result<IntelligentContext> {
        crate::log_debug!(
            "üîç Orchestrator: Parsing intelligence result ({} chars)",
            result.len()
        );

        // Get git context for fallback
        let git_context = context.git_repo.get_git_info(&context.config).await?;

        // Try to parse JSON response using our parser
        let parsed_response: serde_json::Value = self.parser.parse_json_response(result)?;

        let files_with_relevance: Vec<FileRelevance> = parsed_response
            .get("files")
            .and_then(|f| f.as_array())
            .map_or_else(
                || {
                    // Fallback: create basic context with equal relevance
                    crate::log_debug!("‚ö†Ô∏è Orchestrator: Using fallback file analysis");
                    git_context
                        .staged_files
                        .iter()
                        .map(|file| FileRelevance {
                            path: file.path.clone(),
                            relevance_score: 0.7,
                            analysis: format!("File {} was modified", file.path),
                            key_changes: vec!["Content changes detected".to_string()],
                            impact_assessment: "Part of the overall changeset".to_string(),
                        })
                        .collect()
                },
                |files| {
                    crate::log_debug!(
                        "üìä Orchestrator: Processing {} file analyses from LLM",
                        files.len()
                    );
                    files
                        .iter()
                        .filter_map(|file| {
                            Some(FileRelevance {
                                path: file.get("path")?.as_str()?.to_string(),
                                #[allow(clippy::cast_possible_truncation, clippy::as_conversions)]
                                relevance_score: file.get("relevance_score")?.as_f64()? as f32,
                                analysis: file.get("analysis")?.as_str()?.to_string(),
                                key_changes: file
                                    .get("key_changes")?
                                    .as_array()?
                                    .iter()
                                    .filter_map(|v| v.as_str().map(ToString::to_string))
                                    .collect(),
                                impact_assessment: file
                                    .get("impact_assessment")?
                                    .as_str()?
                                    .to_string(),
                            })
                        })
                        .collect()
                },
            );

        let change_summary = parsed_response
            .get("change_summary")
            .and_then(|v| v.as_str())
            .unwrap_or("Changes analyzed")
            .to_string();

        let technical_analysis = parsed_response
            .get("technical_analysis")
            .and_then(|v| v.as_str())
            .unwrap_or("Technical implementation details")
            .to_string();

        let project_insights = parsed_response
            .get("project_insights")
            .and_then(|v| v.as_str())
            .unwrap_or("Project context and fit")
            .to_string();

        crate::log_debug!(
            "üìã Orchestrator: Parsed {} files with relevance scores",
            files_with_relevance.len()
        );

        Ok(IntelligentContext {
            files_with_relevance,
            change_summary,
            technical_analysis,
            project_insights,
        })
    }

    /// Gather intelligent context (wrapper for compatibility)
    pub async fn gather_intelligent_context(
        &self,
        context: &AgentContext,
    ) -> Result<IntelligentContext> {
        self.gather_context_with_tools(context).await
    }

    /// Build commit context from agent context and intelligent context
    pub async fn build_commit_context(
        &self,
        context: &AgentContext,
        _intelligent_context: &IntelligentContext,
    ) -> Result<CommitContext> {
        // Create a basic commit context using the git repo
        let git_repo = &context.git_repo;
        let config = &context.config;

        // This is a simplified version - in a real implementation,
        // you'd want to properly construct the CommitContext
        let commit_context = git_repo.get_git_info(config).await?;

        // For now, return a basic context - this could be enhanced
        // to incorporate the intelligent context data
        Ok(commit_context)
    }
}
